{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Algorithms-and-Data-Structures/blob/master/Covestro_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w45ouVIZUE4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da6d1272-7b93-4aca-8fd5-e47a4f215ed1"
      },
      "source": [
        "# Mounting the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8lmlSyrUdFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5dc0ea50-9b1d-4ab3-bcd7-5f983cc9020a"
      },
      "source": [
        "#install library\n",
        "!pip install python-resize-image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-resize-image in /usr/local/lib/python3.6/dist-packages (1.1.19)\n",
            "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from python-resize-image) (6.2.1)\n",
            "Requirement already satisfied: requests>=2.19.1 in /usr/local/lib/python3.6/dist-packages (from python-resize-image) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (2019.9.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FkqyJHwUfdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing all the libraries\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from PIL import Image\n",
        "import glob\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from resizeimage import resizeimage\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "import keras\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phus7ajYUsgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to Load Images. Returns all the images in a directory in a list format\n",
        "def load_images(path):\n",
        "    image_list = []\n",
        " \n",
        "    for filename in glob.glob(path): \n",
        "        im=Image.open(filename)\n",
        "        image_list.append([filename[::-1][:filename[::-1].find('/')][::-1],im])\n",
        "    \n",
        "    return image_list "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAeDmyQNVADv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to convert images to array. Returns a Numpy array of all the images \n",
        "def image_to_array(img_list):\n",
        "    img_array = []\n",
        "    for i in range(len(img_list)): \n",
        "        img_array.append(img_to_array(img_list[i][1]))\n",
        "\n",
        "    img_array = np.array(img_array) \n",
        "    return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzNWfx3nVYSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to extract names of images and their ratings from the.csv file. Returns a dictionary that has the files names of images and their ratings \n",
        "def parse_meta_data(path):\n",
        "      rows = []\n",
        "      with open(path) as csv_file:\n",
        "          csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "          line_count = 0\n",
        "          for row in csv_reader:\n",
        "            if line_count == 0:\n",
        "                  line_count += 1\n",
        "            else:\n",
        "                  rows.append(row)\n",
        "      meta_data = {}\n",
        "      for i in range(len(rows)):\n",
        "          meta_data[rows[i][0]+'.bmp'] = rows[i][-1]     \n",
        "      return meta_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjps_qk3VYbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to get the images and ratings and segregate them into x_train and y_train. \n",
        "def get_train_data(meta_data,img_list):\n",
        "  ratings = []\n",
        "  img_array = []\n",
        "  for i in range(len(img_list)):\n",
        "     ratings.append(float(meta_data[img_list[i][0]]))\n",
        "     img_array.append(img_to_array(img_list[i][1]))\n",
        "  ratings = np.array(ratings)\n",
        "  img_array = np.array(img_array)\n",
        "  return img_array,ratings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWi-x_b5V4QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to crop the images\n",
        "def CropImage(im):\n",
        "\n",
        "    # by finding greatest changes in gradient of average column intensity\n",
        "    # in a transposed image the location of the horizontal borders can be\n",
        "    # found\n",
        "\n",
        "    window = 30 #size of the gradient over intensity space\n",
        "    im = im.T \n",
        "    averageIntensity = [] #average column intensity over transposed image\n",
        "\n",
        "    # determing average intensity of column in transposed space\n",
        "    for col in range(0,len(im[0])):\n",
        "        averageIntensity.append(np.mean(im[:,col]))\n",
        "\n",
        "    # calculating gradient of intensity over all columns analyzed                  \n",
        "    gradient = np.zeros(len(averageIntensity)-window)\n",
        "    for i in range(0,len(averageIntensity)-window):\n",
        "        gradient[i] = (averageIntensity[i+window] - averageIntensity[i])/window\n",
        "\n",
        "    # edge is found at greatest change in intensity  \n",
        "    cropCol = np.argmax(abs(gradient))\n",
        "   \n",
        "    # apply the crop at the edge \n",
        "    if cropCol < 200:\n",
        "        im = im[:,cropCol:]\n",
        "    elif cropCol > 500:\n",
        "        im = im[:,0:cropCol]\n",
        "\n",
        "    return im.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pc3XnBCVwoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to resize the crop image. Returns an array of cropped images as Numpy vector\n",
        "def crop_resize_image(img_list):\n",
        "    img_array = []\n",
        "    for i in range(len(img_list)):\n",
        "        cover = CropImage(img_list[i])\n",
        "        cover = array_to_img(cover)\n",
        "        cover = resizeimage.resize_cover(cover, [100, 150])\n",
        "        img_array.append(img_to_array(cover))  \n",
        "    \n",
        "    img_array = np.array(img_array)\n",
        "  \n",
        "    return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NovNxLRZLfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to resize the original image\n",
        "def resize_image(img_list):\n",
        "    img_array = []\n",
        "    for i in range(len(img_list)):\n",
        "        cover = array_to_img(img_list[i])\n",
        "        cover = resizeimage.resize_cover(cover, [100, 150])\n",
        "        img_array.append(img_to_array(cover))\n",
        "    img_array = np.array(img_array)\n",
        " \n",
        "    return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa9KEdMxV9Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to convert one channel image to three channel image (To be used for Transfer Learning)\n",
        "def one_channel_2_three_channel(img_array):\n",
        "   new_array = np.zeros((img_array.shape[0],img_array.shape[1],img_array.shape[2],3))\n",
        "   for i in range(len(img_array)):\n",
        "      new = np.stack((img_array[i],)*3, axis=-2)\n",
        "      new_array[i] = np.squeeze( new, axis=-1)\n",
        "   return new_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5HCHs0PWmFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the image files and doing some preprocessing\n",
        "train_image_list = load_images('/content/drive/My Drive/StudentData/train/*.bmp')\n",
        "test_image_list = load_images('/content/drive/My Drive/StudentData/test/*.bmp')\n",
        "train_meta_data = parse_meta_data('/content/drive/My Drive/StudentData/train_scores.csv')\n",
        "\n",
        "x_train,y_train = get_train_data(train_meta_data,train_image_list)\n",
        "x_test = image_to_array(test_image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvQlhCYfW8Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cropping the images. Donot use this block if you do not want to crop the images.\n",
        "train_x = crop_resize_image(x_train)\n",
        "test_x = crop_resize_image(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED7kNoG8Zy_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Resizing the images. Donot run this block if you ran the above (croping image) block\n",
        "x_train = resize_image(x_train)\n",
        "x_test = resize_image(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAC5lVrOXI3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting one channel image to three channel images to be used later. Change the inputs to train_x and test_x if using the cropping image block\n",
        "x_train_2 = one_channel_2_three_channel(train_x)\n",
        "x_test_2 = one_channel_2_three_channel(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYmucaacjQu2",
        "colab_type": "text"
      },
      "source": [
        "# **The Model that consistently gave us best results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKAZ5lX-Vn44",
        "colab_type": "text"
      },
      "source": [
        "## **Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiMMMXRnjXpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementing the model\n",
        "base_model1=ResNet50(include_top=False, weights= 'imagenet', pooling='avg')\n",
        "\n",
        "base_model1.trainable = False\n",
        "\n",
        "x = Dense(256, activation='relu')(base_model1.output)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(1)(x)\n",
        "\n",
        "transfer_model = Model(base_model1.input, x) \n",
        "transfer_model.compile(optimizer ='adam',\n",
        "             loss = 'mean_squared_error', \n",
        "             metrics = ['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3sN3H32jpKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4efed790-64e4-47d5-bef0-e6489fd4cbc9"
      },
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, mode='auto')\n",
        "history = transfer_model.fit(x_train_2, y_train, batch_size=32, epochs=50, verbose=1, callbacks=[reduce_lr], validation_split=0.05, shuffle=True,use_multiprocessing=True)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 187 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "187/187 [==============================] - 21s 112ms/step - loss: 12.0626 - mean_absolute_error: 2.7782 - val_loss: 17.1219 - val_mean_absolute_error: 3.1938\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 3.1140 - mean_absolute_error: 1.4215 - val_loss: 51.0471 - val_mean_absolute_error: 3.6097\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 2.3654 - mean_absolute_error: 1.2306 - val_loss: 19.7678 - val_mean_absolute_error: 2.8409\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 2.6931 - mean_absolute_error: 1.2048 - val_loss: 25.2666 - val_mean_absolute_error: 2.6561\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 2.2619 - mean_absolute_error: 1.1825 - val_loss: 2.5441 - val_mean_absolute_error: 1.1058\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.6912 - mean_absolute_error: 1.0297 - val_loss: 0.8763 - val_mean_absolute_error: 0.7105\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.9607 - mean_absolute_error: 0.7997 - val_loss: 1.3586 - val_mean_absolute_error: 1.0930\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.1018 - mean_absolute_error: 0.8272 - val_loss: 2.3032 - val_mean_absolute_error: 1.3144\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.2166 - mean_absolute_error: 0.8775 - val_loss: 1.1299 - val_mean_absolute_error: 0.9157\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.2221 - mean_absolute_error: 0.8600 - val_loss: 4.8371 - val_mean_absolute_error: 1.9803\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.3913 - mean_absolute_error: 0.9150 - val_loss: 2.2570 - val_mean_absolute_error: 1.2851\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8741 - mean_absolute_error: 0.7131 - val_loss: 3.4640 - val_mean_absolute_error: 1.6168\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.0759 - mean_absolute_error: 0.8057 - val_loss: 2.7813 - val_mean_absolute_error: 1.4455\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8177 - mean_absolute_error: 0.6914 - val_loss: 1.9692 - val_mean_absolute_error: 1.2376\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6217 - mean_absolute_error: 0.6141 - val_loss: 1.1026 - val_mean_absolute_error: 0.9339\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6450 - mean_absolute_error: 0.6261 - val_loss: 0.9785 - val_mean_absolute_error: 0.8768\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.9588 - mean_absolute_error: 0.7598 - val_loss: 0.8492 - val_mean_absolute_error: 0.8121\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7333 - mean_absolute_error: 0.6106 - val_loss: 0.7243 - val_mean_absolute_error: 0.7441\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7908 - mean_absolute_error: 0.6880 - val_loss: 0.6090 - val_mean_absolute_error: 0.6719\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7670 - mean_absolute_error: 0.6685 - val_loss: 0.5264 - val_mean_absolute_error: 0.6141\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7729 - mean_absolute_error: 0.6793 - val_loss: 0.4571 - val_mean_absolute_error: 0.5709\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7080 - mean_absolute_error: 0.6399 - val_loss: 0.3941 - val_mean_absolute_error: 0.5243\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 1.0164 - mean_absolute_error: 0.7849 - val_loss: 0.3487 - val_mean_absolute_error: 0.4861\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7310 - mean_absolute_error: 0.6845 - val_loss: 0.3139 - val_mean_absolute_error: 0.4601\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7021 - mean_absolute_error: 0.6668 - val_loss: 0.2869 - val_mean_absolute_error: 0.4391\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6897 - mean_absolute_error: 0.6235 - val_loss: 0.2754 - val_mean_absolute_error: 0.4292\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7793 - mean_absolute_error: 0.7021 - val_loss: 0.2677 - val_mean_absolute_error: 0.4198\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7926 - mean_absolute_error: 0.6881 - val_loss: 0.2532 - val_mean_absolute_error: 0.4016\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8692 - mean_absolute_error: 0.7232 - val_loss: 0.2441 - val_mean_absolute_error: 0.3871\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.5448 - mean_absolute_error: 0.5865 - val_loss: 0.2366 - val_mean_absolute_error: 0.3743\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6604 - mean_absolute_error: 0.6165 - val_loss: 0.2435 - val_mean_absolute_error: 0.3771\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7040 - mean_absolute_error: 0.6439 - val_loss: 0.2532 - val_mean_absolute_error: 0.3833\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6479 - mean_absolute_error: 0.6295 - val_loss: 0.2535 - val_mean_absolute_error: 0.3831\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7244 - mean_absolute_error: 0.6450 - val_loss: 0.2420 - val_mean_absolute_error: 0.3709\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8030 - mean_absolute_error: 0.7079 - val_loss: 0.2341 - val_mean_absolute_error: 0.3617\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6114 - mean_absolute_error: 0.6139 - val_loss: 0.2230 - val_mean_absolute_error: 0.3473\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7114 - mean_absolute_error: 0.6503 - val_loss: 0.2140 - val_mean_absolute_error: 0.3331\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8274 - mean_absolute_error: 0.6998 - val_loss: 0.2097 - val_mean_absolute_error: 0.3249\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7346 - mean_absolute_error: 0.6763 - val_loss: 0.1999 - val_mean_absolute_error: 0.3063\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6638 - mean_absolute_error: 0.6524 - val_loss: 0.1940 - val_mean_absolute_error: 0.2891\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8826 - mean_absolute_error: 0.7044 - val_loss: 0.1923 - val_mean_absolute_error: 0.2785\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6928 - mean_absolute_error: 0.6493 - val_loss: 0.1957 - val_mean_absolute_error: 0.2818\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6263 - mean_absolute_error: 0.6062 - val_loss: 0.2011 - val_mean_absolute_error: 0.2846\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.5911 - mean_absolute_error: 0.6078 - val_loss: 0.2032 - val_mean_absolute_error: 0.2859\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.8291 - mean_absolute_error: 0.6948 - val_loss: 0.2096 - val_mean_absolute_error: 0.2988\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7305 - mean_absolute_error: 0.6670 - val_loss: 0.2044 - val_mean_absolute_error: 0.2839\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7670 - mean_absolute_error: 0.6669 - val_loss: 0.2036 - val_mean_absolute_error: 0.2812\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6174 - mean_absolute_error: 0.6358 - val_loss: 0.2021 - val_mean_absolute_error: 0.2773\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.7441 - mean_absolute_error: 0.6463 - val_loss: 0.2015 - val_mean_absolute_error: 0.2750\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 1s 4ms/step - loss: 0.6537 - mean_absolute_error: 0.6262 - val_loss: 0.2010 - val_mean_absolute_error: 0.2712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tReUG1BR_arf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b8617180-a857-479a-9920-5e4002d1ed6a"
      },
      "source": [
        "#Visualizing the Loss over the epochs\n",
        "%matplotlib inline\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(loss)) #No. of epochs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#Plot training and validation loss per epoch\n",
        "plt.plot(epochs,loss,'b',label='Training Loss')\n",
        "plt.plot(epochs,val_loss,'r',label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CW25Eaoa2NB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = transfer_model.predict(x_test_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ojAakTjJnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('team13submission.csv', 'w') as file:\n",
        "    file.write('image,total_rating\\n')\n",
        "    for i in range(len(x_test)):\n",
        "        file.write(str(test_image_list[i][0][:-4])+','+str(test_pred[i][0])+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx9j-iXYSEEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "transfer_model.save('/content/drive/My Drive/my_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQtvzk84l2Mi",
        "colab_type": "text"
      },
      "source": [
        "# **Models that we tried but did not give us best results** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e99oGVfxYfFg",
        "colab_type": "text"
      },
      "source": [
        "## **Simple Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Med8XQYd_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1362ba74-1c79-497c-9a2d-798ee514b335"
      },
      "source": [
        "# Developing the model\n",
        "model1 = tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,100,1)),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=[3,3]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=[3,3]),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "       \n",
        "    tf.keras.layers.Dense(256,activation='relu'),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYRAuoc8YKmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6bd4f45-c14c-4238-a20a-46c18fdb7913"
      },
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "model1.compile(optimizer='adam',loss='mean_squared_error',metrics=['mae'])\n",
        "model1.fit(x_train, y_train, batch_size=32, epochs=50, verbose=1, callbacks=[reduce_lr], validation_split=0.05, shuffle=True,use_multiprocessing=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 187 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "187/187 [==============================] - 2s 11ms/sample - loss: 24.6640 - mean_absolute_error: 4.1672 - val_loss: 19.4231 - val_mean_absolute_error: 3.0189\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 0s 769us/sample - loss: 8.1302 - mean_absolute_error: 2.0875 - val_loss: 10.4806 - val_mean_absolute_error: 2.5819\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 0s 775us/sample - loss: 6.4380 - mean_absolute_error: 1.9941 - val_loss: 9.5553 - val_mean_absolute_error: 2.4235\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 0s 767us/sample - loss: 4.7645 - mean_absolute_error: 1.7778 - val_loss: 7.3668 - val_mean_absolute_error: 2.3308\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 0s 759us/sample - loss: 4.4885 - mean_absolute_error: 1.7492 - val_loss: 4.5341 - val_mean_absolute_error: 1.8512\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 0s 769us/sample - loss: 3.6794 - mean_absolute_error: 1.5916 - val_loss: 3.5775 - val_mean_absolute_error: 1.4585\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 0s 757us/sample - loss: 3.4800 - mean_absolute_error: 1.4946 - val_loss: 4.5016 - val_mean_absolute_error: 2.0229\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 0s 760us/sample - loss: 2.8249 - mean_absolute_error: 1.3369 - val_loss: 3.8512 - val_mean_absolute_error: 1.8911\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 0s 767us/sample - loss: 2.4116 - mean_absolute_error: 1.2556 - val_loss: 4.8822 - val_mean_absolute_error: 2.0596\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 0s 778us/sample - loss: 2.3887 - mean_absolute_error: 1.2496 - val_loss: 3.9055 - val_mean_absolute_error: 1.8717\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 0s 756us/sample - loss: 1.9332 - mean_absolute_error: 1.1205 - val_loss: 3.2067 - val_mean_absolute_error: 1.7147\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 0s 774us/sample - loss: 1.9522 - mean_absolute_error: 1.1302 - val_loss: 2.3407 - val_mean_absolute_error: 1.4762\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 0s 773us/sample - loss: 1.5518 - mean_absolute_error: 0.9611 - val_loss: 1.1668 - val_mean_absolute_error: 0.9345\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 0s 766us/sample - loss: 1.1220 - mean_absolute_error: 0.8280 - val_loss: 0.8789 - val_mean_absolute_error: 0.6780\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 0s 771us/sample - loss: 0.9347 - mean_absolute_error: 0.7537 - val_loss: 0.9491 - val_mean_absolute_error: 0.8485\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 0s 758us/sample - loss: 0.8573 - mean_absolute_error: 0.7055 - val_loss: 0.7634 - val_mean_absolute_error: 0.6798\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 0s 779us/sample - loss: 0.6628 - mean_absolute_error: 0.6360 - val_loss: 0.6061 - val_mean_absolute_error: 0.6720\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 0s 773us/sample - loss: 0.5687 - mean_absolute_error: 0.5559 - val_loss: 0.5786 - val_mean_absolute_error: 0.6059\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 0s 787us/sample - loss: 0.4443 - mean_absolute_error: 0.5015 - val_loss: 0.5346 - val_mean_absolute_error: 0.6848\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 0s 772us/sample - loss: 0.2858 - mean_absolute_error: 0.3975 - val_loss: 0.3575 - val_mean_absolute_error: 0.5220\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 0s 784us/sample - loss: 0.2652 - mean_absolute_error: 0.3778 - val_loss: 0.4197 - val_mean_absolute_error: 0.5406\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 0s 770us/sample - loss: 0.2257 - mean_absolute_error: 0.3693 - val_loss: 0.4572 - val_mean_absolute_error: 0.4848\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 0s 775us/sample - loss: 0.2734 - mean_absolute_error: 0.4097 - val_loss: 0.5363 - val_mean_absolute_error: 0.4728\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 0s 770us/sample - loss: 0.3002 - mean_absolute_error: 0.4333 - val_loss: 0.3306 - val_mean_absolute_error: 0.4935\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 0s 764us/sample - loss: 0.2383 - mean_absolute_error: 0.3731 - val_loss: 0.4022 - val_mean_absolute_error: 0.5362\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 0s 790us/sample - loss: 0.2089 - mean_absolute_error: 0.3439 - val_loss: 0.5443 - val_mean_absolute_error: 0.6588\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 0s 761us/sample - loss: 0.1188 - mean_absolute_error: 0.2565 - val_loss: 0.4386 - val_mean_absolute_error: 0.5928\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 0s 778us/sample - loss: 0.0883 - mean_absolute_error: 0.2157 - val_loss: 0.3467 - val_mean_absolute_error: 0.5017\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 0s 760us/sample - loss: 0.0700 - mean_absolute_error: 0.1907 - val_loss: 0.3141 - val_mean_absolute_error: 0.4882\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 0s 774us/sample - loss: 0.0650 - mean_absolute_error: 0.1964 - val_loss: 0.3070 - val_mean_absolute_error: 0.4654\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 0s 763us/sample - loss: 0.0528 - mean_absolute_error: 0.1562 - val_loss: 0.3245 - val_mean_absolute_error: 0.4709\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 0s 770us/sample - loss: 0.0529 - mean_absolute_error: 0.1805 - val_loss: 0.2682 - val_mean_absolute_error: 0.4165\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 0s 765us/sample - loss: 0.0789 - mean_absolute_error: 0.2165 - val_loss: 0.2610 - val_mean_absolute_error: 0.3656\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 0s 764us/sample - loss: 0.1011 - mean_absolute_error: 0.2608 - val_loss: 0.4143 - val_mean_absolute_error: 0.5006\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 0s 767us/sample - loss: 0.0924 - mean_absolute_error: 0.2479 - val_loss: 0.3064 - val_mean_absolute_error: 0.3937\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 0s 762us/sample - loss: 0.0665 - mean_absolute_error: 0.2024 - val_loss: 0.3197 - val_mean_absolute_error: 0.4445\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 0s 764us/sample - loss: 0.0561 - mean_absolute_error: 0.1901 - val_loss: 0.4703 - val_mean_absolute_error: 0.5601\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 0s 758us/sample - loss: 0.0440 - mean_absolute_error: 0.1706 - val_loss: 0.2855 - val_mean_absolute_error: 0.4246\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 0s 762us/sample - loss: 0.0395 - mean_absolute_error: 0.1481 - val_loss: 0.4486 - val_mean_absolute_error: 0.5584\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 0s 777us/sample - loss: 0.0334 - mean_absolute_error: 0.1366 - val_loss: 0.4014 - val_mean_absolute_error: 0.5253\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 0s 771us/sample - loss: 0.0252 - mean_absolute_error: 0.1156 - val_loss: 0.2230 - val_mean_absolute_error: 0.4045\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 0s 771us/sample - loss: 0.0228 - mean_absolute_error: 0.1120 - val_loss: 0.4116 - val_mean_absolute_error: 0.5329\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 0s 766us/sample - loss: 0.0173 - mean_absolute_error: 0.1019 - val_loss: 0.3279 - val_mean_absolute_error: 0.4593\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 0s 771us/sample - loss: 0.0162 - mean_absolute_error: 0.0964 - val_loss: 0.3894 - val_mean_absolute_error: 0.5008\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 0s 760us/sample - loss: 0.0110 - mean_absolute_error: 0.0737 - val_loss: 0.2943 - val_mean_absolute_error: 0.4384\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 0s 769us/sample - loss: 0.0072 - mean_absolute_error: 0.0584 - val_loss: 0.3337 - val_mean_absolute_error: 0.4727\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 0s 770us/sample - loss: 0.0067 - mean_absolute_error: 0.0569 - val_loss: 0.3401 - val_mean_absolute_error: 0.4625\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 0s 763us/sample - loss: 0.0054 - mean_absolute_error: 0.0515 - val_loss: 0.3292 - val_mean_absolute_error: 0.4557\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 0s 764us/sample - loss: 0.0045 - mean_absolute_error: 0.0459 - val_loss: 0.3397 - val_mean_absolute_error: 0.4615\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 0s 775us/sample - loss: 0.0042 - mean_absolute_error: 0.0425 - val_loss: 0.3529 - val_mean_absolute_error: 0.4706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12d3bef6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQa7i4jRkph_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model1.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC3m3jM0lHx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('team13submission.csv', 'w') as file:\n",
        "    file.write('image,total_rating\\n')\n",
        "    for i in range(len(x_test)):\n",
        "        file.write(str(test_image_list[i][0][:-4])+','+str(test_pred[i][0])+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsPf3-YglNII",
        "colab_type": "text"
      },
      "source": [
        "##**Transfer Learning and Random Forests Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe_hcanlozGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model2=ResNet50(include_top=False, weights= 'imagenet', pooling='avg')\n",
        "\n",
        "base_model2.trainable = False\n",
        "\n",
        "x = Dense(4096, activation='relu')(base_model2.output)\n",
        "\n",
        "transfer_model1 = Model(base_model2.input, x) \n",
        "transfer_model1.compile(optimizer ='adam',\n",
        "             loss = 'mean_squared_error', \n",
        "             metrics = ['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HgcBDZTo9KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_output = transfer_model1.predict(x_train_2)\n",
        "test_output = transfer_model1.predict(x_test_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIRwJl1JpEtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f95f56dd-ebd9-427b-9aa9-5c8318acc9ce"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf=RandomForestRegressor(n_estimators= 200)\n",
        "rf.fit(train_output,y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                      n_jobs=None, oob_score=False, random_state=None,\n",
              "                      verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PBAqfXUpxnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = rf.predict(test_output )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6goj945u45F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('team13submission.csv', 'w') as file:\n",
        "    file.write('image,total_rating\\n')\n",
        "    for i in range(len(x_test)):\n",
        "        file.write(str(test_image_list[i][0][:-4])+','+str(test_pred[i])+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}